"use strict";
/*
 * Copyright (c) 2020, salesforce.com, inc.
 * All rights reserved.
 * Licensed under the BSD 3-Clause license.
 * For full license text, see LICENSE.txt file in the repo root or https://opensource.org/licenses/BSD-3-Clause
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.TokensHandler = exports.SandboxesHandler = exports.AliasesHandler = exports.AuthHandler = exports.SfdxDataHandler = void 0;
const path_1 = require("path");
const fs = require("fs");
const kit_1 = require("@salesforce/kit");
const ts_types_1 = require("@salesforce/ts-types");
const global_1 = require("../global");
const configFile_1 = require("../config/configFile");
const sandboxOrgConfig_1 = require("../config/sandboxOrgConfig");
const globalInfoConfig_1 = require("./globalInfoConfig");
const types_1 = require("./types");
function isEqual(object1, object2) {
    const keys1 = Object.keys(object1).filter((k) => k !== 'timestamp');
    const keys2 = Object.keys(object2).filter((k) => k !== 'timestamp');
    if (keys1.length !== keys2.length)
        return false;
    for (const key of keys1) {
        if (object1[key] !== object2[key])
            return false;
    }
    return true;
}
class SfdxDataHandler {
    constructor() {
        this.handlers = [new AuthHandler(), new AliasesHandler(), new SandboxesHandler(), new TokensHandler()];
    }
    async write(latest = globalInfoConfig_1.GlobalInfo.emptyDataModel) {
        await Promise.all(this.handlers.map((handler) => handler.write(latest, this.original)));
        this.setOriginal(latest);
    }
    async merge(sfData = globalInfoConfig_1.GlobalInfo.emptyDataModel) {
        let merged = (0, globalInfoConfig_1.deepCopy)(sfData);
        for (const handler of this.handlers) {
            merged = Object.assign(merged, await handler.merge(merged));
        }
        this.setOriginal(merged);
        return merged;
    }
    setOriginal(data) {
        this.original = (0, globalInfoConfig_1.deepCopy)(data);
    }
}
exports.SfdxDataHandler = SfdxDataHandler;
class BaseHandler {
    async merge(sfData = globalInfoConfig_1.GlobalInfo.emptyDataModel) {
        const sfdxData = await this.migrate();
        const merged = (0, globalInfoConfig_1.deepCopy)(sfData);
        // Only merge the key this handler is responsible for.
        const key = this.sfKey;
        const sfKeys = Object.keys(sfData[key] ?? {});
        const sfdxKeys = Object.keys(sfdxData[key] ?? {});
        const commonKeys = sfKeys.filter((k) => sfdxKeys.includes(k));
        for (const k of commonKeys) {
            const [newer, older] = [sfData[key][k], sfdxData[key][k]].sort((a, b) => {
                if ((0, ts_types_1.isPlainObject)(a) && (0, ts_types_1.isPlainObject)(b))
                    return new Date(a.timestamp) < new Date(b.timestamp) ? 1 : -1;
                return 0;
            });
            (0, kit_1.set)(merged, `${key}["${k}"]`, Object.assign({}, older, newer));
        }
        // Keys that exist in .sfdx but not .sf are added because we assume
        // that this means the key was created using sfdx.
        // However, this is not always a valid assumption because it could
        // also mean that the key was deleted using sf, in which case we
        // do not want to migrate the sfdx key to sf.
        // Programmatically differentiating between a new key and a deleted key
        // would be nearly impossible. Instead, we should ensure that whenever
        // sf deletes a key it also deletes it in sfdx. This way, we can safely
        // assume that we should migrate any keys that exist in in .sfdx
        const unhandledSfdxKeys = sfdxKeys.filter((k) => !sfKeys.includes(k));
        for (const k of unhandledSfdxKeys) {
            (0, kit_1.set)(merged, `${key}["${k}"]`, sfdxData[key][k]);
        }
        // Keys that exist in .sf but not .sfdx are deleted because we assume
        // that this means the key was deleted while using sfdx.
        // We can make this assumption because keys that are created by sf will
        // always be migrated back to sfdx
        const unhandledSfKeys = sfKeys.filter((k) => !sfdxKeys.includes(k));
        for (const k of unhandledSfKeys) {
            delete merged[key][k];
        }
        return merged;
    }
}
class AuthHandler extends BaseHandler {
    constructor() {
        super(...arguments);
        this.sfKey = types_1.SfInfoKeys.ORGS;
    }
    async migrate() {
        const oldAuths = await this.listAllAuthorizations();
        const newAuths = oldAuths.reduce((x, y) => Object.assign(x, { [(0, ts_types_1.ensureString)(y.username)]: y }), {});
        return { [this.sfKey]: newAuths };
    }
    async write(latest, original) {
        const { changed, deleted } = await this.findChanges(latest, original);
        await Promise.all(Object.entries(changed)
            .filter(([, authData]) => authData)
            .map(async ([username, authData]) => {
            const config = await this.createAuthFileConfig(username);
            config.setContentsFromObject(authData);
            return config.write();
        }));
        await Promise.all(deleted.map(async (username) => {
            const config = await this.createAuthFileConfig(username);
            return config.unlink();
        }));
    }
    async findChanges(latest, original) {
        const latestAuths = latest.orgs;
        const originalAuths = original.orgs;
        const changed = {};
        for (const [username, auth] of Object.entries(latestAuths)) {
            const originalAuth = originalAuths[username] ?? {};
            if (!isEqual(auth, originalAuth)) {
                changed[username] = auth;
            }
        }
        const deleted = Object.keys(originalAuths).filter((username) => !latestAuths[username]);
        return { changed, deleted };
    }
    async createAuthFileConfig(username) {
        const config = await configFile_1.ConfigFile.create({
            filename: `${username}.json`,
            isGlobal: true,
            isState: true,
            stateFolder: global_1.Global.SFDX_STATE_FOLDER,
            throwOnNotFound: false,
            encryptedKeys: ['accessToken', 'refreshToken', 'password', 'clientSecret'],
        });
        return config;
    }
    async listAllAuthFiles() {
        const globalFiles = await fs.promises.readdir(global_1.Global.SFDX_DIR);
        return globalFiles.filter((file) => file.match(AuthHandler.authFilenameFilterRegEx));
    }
    async listAllAuthorizations() {
        const filenames = await this.listAllAuthFiles();
        return Promise.all(filenames
            .map((f) => (0, path_1.basename)(f, (0, path_1.extname)(f)))
            .map(async (username) => {
            const configFile = await this.createAuthFileConfig(username);
            const contents = configFile.getContents();
            const stat = await configFile.stat();
            return { ...contents, timestamp: stat.mtime.toISOString() };
        }));
    }
}
exports.AuthHandler = AuthHandler;
// The regular expression that filters files stored in $HOME/.sfdx
AuthHandler.authFilenameFilterRegEx = /^[^.][^@]*@[^.]+(\.[^.\s]+)+\.json$/;
class AliasesHandler extends BaseHandler {
    constructor() {
        super(...arguments);
        this.sfKey = types_1.SfInfoKeys.ALIASES;
    }
    async migrate() {
        const aliasesFilePath = (0, path_1.join)(global_1.Global.SFDX_DIR, AliasesHandler.SFDX_ALIASES_FILENAME);
        try {
            const x = await fs.promises.readFile(aliasesFilePath, 'utf8');
            const sfdxAliases = (0, kit_1.parseJson)(x).orgs;
            return { [this.sfKey]: { ...sfdxAliases } };
        }
        catch (e) {
            return { [this.sfKey]: {} };
        }
    }
    // AliasesHandler implements its own merge method because the structure of aliases is flat instead of nested by SfInfoKey types.
    async merge(sfData = globalInfoConfig_1.GlobalInfo.emptyDataModel) {
        const sfdxAliases = (await this.migrate())[types_1.SfInfoKeys.ALIASES];
        const merged = (0, globalInfoConfig_1.deepCopy)(sfData);
        /* Overwrite `sf` aliases with `sfdx` aliases
         *  `sf` will always modify `sfdx` files but `sfdx` won't modify `sf` files
         *  because of this we can assume that any changes in `sfdx` files that aren't
         *  in `sf` are the latest data
         *
         *  This breaks down if a user of `sf` manually modifies the `~/.sf/sf.json` file
         *  but we don't support that use case out-of-the-box (yet?)
         *
         *  Note: See also the explanation on the merge method in the BaseHandler class
         */
        Object.keys(sfdxAliases).forEach((alias) => {
            merged[types_1.SfInfoKeys.ALIASES][alias] = sfdxAliases[alias];
        });
        /* Delete any aliases that don't exist in sfdx config files
         *  Aliases that exist in .sf but not .sfdx are deleted because we assume
         *  that this means the alias was deleted while using sfdx. We can make
         *  this assumption because keys that are created by sf will always be
         *  migrated back to sfdx.
         *
         *  Note: See also the explanation on the merge method in the BaseHandler class
         */
        for (const alias in merged[types_1.SfInfoKeys.ALIASES]) {
            if (!sfdxAliases[alias])
                delete merged[types_1.SfInfoKeys.ALIASES][alias];
        }
        return merged;
    }
    async write(latest) {
        const aliasesFilePath = (0, path_1.join)(global_1.Global.SFDX_DIR, AliasesHandler.SFDX_ALIASES_FILENAME);
        await fs.promises.writeFile(aliasesFilePath, JSON.stringify({ orgs: latest[types_1.SfInfoKeys.ALIASES] }, null, 2));
    }
}
exports.AliasesHandler = AliasesHandler;
AliasesHandler.SFDX_ALIASES_FILENAME = 'alias.json';
class SandboxesHandler extends BaseHandler {
    constructor() {
        super(...arguments);
        this.sfKey = types_1.SfInfoKeys.SANDBOXES;
    }
    async merge(sfData = globalInfoConfig_1.GlobalInfo.emptyDataModel) {
        const sfdxData = await this.migrate();
        const merged = (0, globalInfoConfig_1.deepCopy)(sfData);
        // Only merge the key this handler is responsible for.
        const key = this.sfKey;
        const sfKeys = Object.keys(sfData[key] ?? {});
        const sfdxKeys = Object.keys(sfdxData[key] ?? {});
        // sandbox entries for .sf and .sfdx contain static data. Given there
        // can be no mutation during the life of the sandbox, having to merge common keys
        // is unnecessary.
        // Keys that exist in .sfdx but not .sf are added because we assume
        // that this means the key was created using sfdx.
        // However, this is not always a valid assumption because it could
        // also mean that the key was deleted using sf, in which case we
        // do not want to migrate the sfdx key to sf.
        // Programmatically differentiating between a new key and a deleted key
        // would be nearly impossible. Instead, we should ensure that whenever
        // sf deletes a key it also deletes it in sfdx. This way, we can safely
        // assume that we should migrate any keys that exist in .sfdx
        const unhandledSfdxKeys = sfdxKeys.filter((k) => !sfKeys.includes(k));
        for (const k of unhandledSfdxKeys) {
            (0, kit_1.set)(merged, `${key}["${k}"]`, sfdxData[key][k]);
        }
        // Keys that exist in .sf but not .sfdx are deleted because we assume
        // that this means the key was deleted while using sfdx.
        // We can make this assumption because keys that are created by sf will
        // always be migrated back to sfdx
        const unhandledSfKeys = sfKeys.filter((k) => !sfdxKeys.includes(k));
        for (const k of unhandledSfKeys) {
            delete merged[key][k];
        }
        return merged;
    }
    async migrate() {
        const oldSandboxes = await this.listAllSandboxes();
        const newSandboxes = Object.fromEntries(oldSandboxes.map((old) => [old.sandboxOrgId, old]));
        return { [this.sfKey]: newSandboxes };
    }
    async write(latest, original) {
        const { changed, deleted } = await this.findChanges(latest, original);
        for (const sandboxData of Object.values(changed)) {
            if (sandboxData) {
                const orgId = sandboxData.sandboxOrgId;
                const sandboxConfig = new sandboxOrgConfig_1.SandboxOrgConfig(sandboxOrgConfig_1.SandboxOrgConfig.getOptions(orgId));
                sandboxConfig.set(sandboxOrgConfig_1.SandboxOrgConfig.Fields.PROD_ORG_USERNAME, sandboxData.prodOrgUsername);
                await sandboxConfig.write();
            }
        }
        for (const username of deleted) {
            const originalSandbox = original.sandboxes[username];
            const orgId = originalSandbox.sandboxOrgId;
            const sandboxConfig = new sandboxOrgConfig_1.SandboxOrgConfig(sandboxOrgConfig_1.SandboxOrgConfig.getOptions(orgId));
            await sandboxConfig.unlink();
        }
    }
    async listAllSandboxFiles() {
        const globalFiles = await fs.promises.readdir(global_1.Global.SFDX_DIR);
        return globalFiles.filter((file) => file.match(SandboxesHandler.sandboxFilenameFilterRegEx));
    }
    async listAllSandboxes() {
        return Promise.all((await this.listAllSandboxFiles()).map(async (filename) => {
            const matches = filename.match(SandboxesHandler.sandboxFilenameFilterRegEx);
            const orgId = matches ? matches[1] : '';
            const sandboxConfig = new sandboxOrgConfig_1.SandboxOrgConfig(sandboxOrgConfig_1.SandboxOrgConfig.getOptions(orgId));
            const stat = await sandboxConfig.stat();
            const contents = { ...(await sandboxConfig.read(true)), sandboxOrgId: orgId };
            const sandbox = Object.assign(contents, { timestamp: stat.mtime.toISOString() });
            return sandbox;
        }));
    }
    async findChanges(latest, original) {
        const latestSandboxes = latest.sandboxes;
        const originalSandboxes = original.sandboxes;
        const changed = {};
        for (const [sandboxOrgId, sandbox] of Object.entries(latestSandboxes)) {
            const originalSandbox = originalSandboxes[sandboxOrgId] ?? {};
            if (!isEqual(sandbox, originalSandbox)) {
                changed[sandboxOrgId] = sandbox;
            }
        }
        const deleted = Object.keys(originalSandboxes).filter((sandboxOrgId) => !latestSandboxes[sandboxOrgId]);
        return { changed, deleted };
    }
}
exports.SandboxesHandler = SandboxesHandler;
// The regular expression that filters files stored in $HOME/.sfdx
SandboxesHandler.sandboxFilenameFilterRegEx = /^(00D.*?)\.sandbox\.json$/;
class TokensHandler extends BaseHandler {
    constructor() {
        super(...arguments);
        this.sfKey = types_1.SfInfoKeys.TOKENS;
    }
    async migrate() {
        const filePath = (0, path_1.join)(global_1.Global.SFDX_DIR, TokensHandler.SFDX_TOKENS_FILENAME);
        try {
            const x = await fs.promises.readFile(filePath, 'utf8');
            const tokens = (0, kit_1.parseJson)(x);
            return { [this.sfKey]: tokens };
        }
        catch (e) {
            return { [this.sfKey]: {} };
        }
    }
    async write(latest) {
        const filePath = (0, path_1.join)(global_1.Global.SFDX_DIR, TokensHandler.SFDX_TOKENS_FILENAME);
        await fs.promises.writeFile(filePath, JSON.stringify(latest[types_1.SfInfoKeys.TOKENS], null, 2));
    }
}
exports.TokensHandler = TokensHandler;
TokensHandler.SFDX_TOKENS_FILENAME = 'tokens.json';
//# sourceMappingURL=sfdxDataHandler.js.map