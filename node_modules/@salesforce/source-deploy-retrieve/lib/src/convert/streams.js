"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.JsToXml = exports.ZipWriter = exports.StandardWriter = exports.ComponentWriter = exports.ComponentConverter = exports.ComponentReader = exports.stream2buffer = exports.pipeline = void 0;
/*
 * Copyright (c) 2020, salesforce.com, inc.
 * All rights reserved.
 * Licensed under the BSD 3-Clause license.
 * For full license text, see LICENSE.txt file in the repo root or https://opensource.org/licenses/BSD-3-Clause
 */
const path_1 = require("path");
const stream_1 = require("stream");
const util_1 = require("util");
const core_1 = require("@salesforce/core");
const archiver_1 = require("archiver");
const graceful_fs_1 = require("graceful-fs");
const fast_xml_parser_1 = require("fast-xml-parser");
const core_2 = require("@salesforce/core");
const resolve_1 = require("../resolve");
const common_1 = require("../common");
const fileSystemHandler_1 = require("../utils/fileSystemHandler");
const transformers_1 = require("./transformers");
const convertContext_1 = require("./convertContext");
core_1.Messages.importMessagesDirectory(__dirname);
const messages = core_1.Messages.load('@salesforce/source-deploy-retrieve', 'sdr', ['error_convert_invalid_format']);
exports.pipeline = (0, util_1.promisify)(stream_1.pipeline);
const stream2buffer = async (stream) => {
    return new Promise((resolve, reject) => {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const buf = Array();
        stream.on('data', (chunk) => buf.push(chunk));
        stream.on('end', () => resolve(Buffer.concat(buf)));
        // eslint-disable-next-line @typescript-eslint/restrict-template-expressions
        stream.on('error', (err) => reject(`error converting stream - ${err}`));
    });
};
exports.stream2buffer = stream2buffer;
class ComponentReader extends stream_1.Readable {
    constructor(components) {
        super({ objectMode: true });
        this.iter = this.createIterator(components);
    }
    _read() {
        let next = this.iter.next();
        while (!next.done) {
            this.push(next.value);
            next = this.iter.next();
        }
        this.push(null);
    }
    *createIterator(components) {
        for (const component of components) {
            yield component;
        }
    }
}
exports.ComponentReader = ComponentReader;
class ComponentConverter extends stream_1.Transform {
    constructor(targetFormat, registry, mergeSet, defaultDirectory) {
        super({ objectMode: true });
        this.context = new convertContext_1.ConvertContext();
        this.targetFormat = targetFormat;
        this.mergeSet = mergeSet;
        this.transformerFactory = new transformers_1.MetadataTransformerFactory(registry, this.context);
        this.defaultDirectory = defaultDirectory;
    }
    async _transform(chunk, encoding, callback) {
        let err;
        const writeInfos = [];
        // Only transform components not marked for delete.
        if (!chunk.isMarkedForDelete()) {
            try {
                const converts = [];
                const transformer = this.transformerFactory.getTransformer(chunk);
                transformer.defaultDirectory = this.defaultDirectory;
                const mergeWith = this.mergeSet?.getSourceComponents(chunk);
                switch (this.targetFormat) {
                    case 'source':
                        if (mergeWith) {
                            for (const mergeComponent of mergeWith) {
                                converts.push(transformer.toSourceFormat(chunk, mergeComponent));
                            }
                        }
                        if (converts.length === 0) {
                            converts.push(transformer.toSourceFormat(chunk));
                        }
                        break;
                    case 'metadata':
                        converts.push(transformer.toMetadataFormat(chunk));
                        break;
                    default:
                        throw new core_1.SfError(messages.getMessage('error_convert_invalid_format', [this.targetFormat]), 'LibraryError');
                }
                // could maybe improve all this with lazy async collections...
                (await Promise.all(converts)).forEach((infos) => writeInfos.push(...infos));
            }
            catch (e) {
                err = e;
            }
        }
        callback(err, { component: chunk, writeInfos });
    }
    /**
     * Called at the end when all components have passed through the pipeline. Finalizers
     * take care of any additional work to be done at this stage e.g. recomposing child components.
     */
    async _flush(callback) {
        let err;
        try {
            for await (const finalizerResult of this.context.executeFinalizers(this.defaultDirectory)) {
                finalizerResult.forEach((result) => this.push(result));
            }
        }
        catch (e) {
            err = e;
        }
        callback(err);
    }
}
exports.ComponentConverter = ComponentConverter;
class ComponentWriter extends stream_1.Writable {
    constructor(rootDestination) {
        super({ objectMode: true });
        this.forceIgnoredPaths = new Set();
        this.rootDestination = rootDestination;
    }
}
exports.ComponentWriter = ComponentWriter;
class StandardWriter extends ComponentWriter {
    constructor(rootDestination, resolver = new resolve_1.MetadataResolver()) {
        super(rootDestination);
        this.converted = [];
        this.resolver = resolver;
        this.logger = core_2.Logger.childFromRoot(this.constructor.name);
    }
    async _write(chunk, encoding, callback) {
        let err;
        if (chunk.writeInfos.length !== 0) {
            try {
                const toResolve = [];
                // it is a reasonable expectation that when a conversion call exits, the files of
                // every component has been written to the destination. This await ensures the microtask
                // queue is empty when that call exits and overall less memory is consumed.
                await Promise.all(chunk.writeInfos.map((info) => {
                    const fullDest = (0, path_1.isAbsolute)(info.output) ? info.output : (0, path_1.join)(this.rootDestination, info.output);
                    if (!(0, graceful_fs_1.existsSync)(fullDest)) {
                        for (const ignoredPath of this.forceIgnoredPaths) {
                            if ((0, path_1.dirname)(ignoredPath).includes((0, path_1.dirname)(fullDest)) &&
                                (0, path_1.basename)(ignoredPath).includes((0, path_1.basename)(fullDest))) {
                                return;
                            }
                        }
                    }
                    if (this.forceIgnoredPaths.has(fullDest)) {
                        return;
                    }
                    // if there are children, resolve each file. o/w just pick one of the files to resolve
                    if (toResolve.length === 0 || chunk.component.type.children) {
                        // This is a workaround for a server side ListViews bug where
                        // duplicate components are sent. W-9614275
                        if (toResolve.includes(fullDest)) {
                            this.logger.debug(`Ignoring duplicate metadata for: ${fullDest}`);
                            return;
                        }
                        toResolve.push(fullDest);
                    }
                    (0, fileSystemHandler_1.ensureFileExists)(fullDest);
                    return (0, exports.pipeline)(info.source, (0, graceful_fs_1.createWriteStream)(fullDest));
                }));
                toResolve.map((fsPath) => {
                    this.converted.push(...this.resolver.getComponentsFromPath(fsPath));
                });
            }
            catch (e) {
                err = e;
            }
        }
        callback(err);
    }
}
exports.StandardWriter = StandardWriter;
class ZipWriter extends ComponentWriter {
    constructor(rootDestination) {
        super(rootDestination);
        // compression-/speed+ (0)<---(3)---------->(9) compression+/speed-
        // 3 appears to be a decent balance of compression and speed. It felt like
        // higher values = diminishing returns on compression and made conversion slower
        this.zip = (0, archiver_1.create)('zip', { zlib: { level: 3 } });
        this.buffers = [];
        void (0, exports.pipeline)(this.zip, this.getOutputStream());
    }
    // required to be async to override Node's Writable class
    // eslint-disable-next-line @typescript-eslint/require-await
    async _write(chunk, encoding, callback) {
        let err;
        try {
            for (const info of chunk.writeInfos) {
                this.addToZip(info.source, info.output);
            }
        }
        catch (e) {
            err = e;
        }
        callback(err);
    }
    async _final(callback) {
        let err;
        try {
            await this.zip.finalize();
        }
        catch (e) {
            err = e;
        }
        callback(err);
    }
    addToZip(contents, path) {
        this.zip.append(contents, { name: path });
    }
    getOutputStream() {
        if (this.rootDestination) {
            return (0, graceful_fs_1.createWriteStream)(this.rootDestination);
        }
        else {
            const bufferWritable = new stream_1.Writable();
            // eslint-disable-next-line no-underscore-dangle
            bufferWritable._write = (chunk, encoding, cb) => {
                this.buffers.push(chunk);
                cb();
            };
            return bufferWritable;
        }
    }
    get buffer() {
        return Buffer.concat(this.buffers);
    }
}
exports.ZipWriter = ZipWriter;
/**
 * Convenient wrapper to serialize a js object to XML content. Implemented as a stream
 * to be used as a valid source for ComponentWriters in the conversion pipeline,
 * even though it's not beneficial in the typical way a stream is.
 */
class JsToXml extends stream_1.Readable {
    constructor(xmlObject) {
        super();
        this.xmlObject = xmlObject;
    }
    _read() {
        const js2Xml = new fast_xml_parser_1.j2xParser({ format: true, indentBy: '    ', ignoreAttributes: false, cdataTagName: '__cdata' });
        const xmlContent = common_1.XML_DECL.concat(js2Xml.parse(this.xmlObject));
        this.push(xmlContent);
        this.push(null);
    }
}
exports.JsToXml = JsToXml;
//# sourceMappingURL=streams.js.map