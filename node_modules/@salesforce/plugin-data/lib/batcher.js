"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Batcher = void 0;
const core_1 = require("@salesforce/core");
const sync_1 = require("csv-stringify/sync");
const parse = require("csv-parse");
// max rows per file in Bulk 1.0
const BATCH_RECORDS_LIMIT = 10000;
/// max characters/bytes per file in Bulk 1.0
const BATCH_BYTES_LIMIT = 10000000;
const POLL_FREQUENCY_MS = 5000;
core_1.Messages.importMessagesDirectory(__dirname);
const messages = core_1.Messages.loadMessages('@salesforce/plugin-data', 'batcher');
class Batcher {
    constructor(conn, ux) {
        this.conn = conn;
        this.ux = ux;
    }
    /**
     * get and display the job status; close the job if completed
     *
     * @param jobId {string}
     * @param doneCallback
     */
    async fetchAndDisplayJobStatus(jobId, doneCallback) {
        const job = this.conn.bulk.job(jobId);
        const jobInfo = await job.check();
        this.bulkStatus(jobInfo, undefined, undefined, true);
        if (doneCallback) {
            doneCallback({ job: jobInfo });
        }
        return jobInfo;
    }
    bulkStatus(summary, results, batchNum, isJob) {
        this.ux.log('');
        if (batchNum) {
            this.ux.styledHeader(messages.getMessage('BulkBatch', [batchNum]));
        }
        if (results) {
            const errorMessages = [];
            results.forEach((result) => {
                if (result.errors) {
                    result.errors.forEach((errMsg) => {
                        errorMessages.push(errMsg);
                    });
                }
            });
            if (errorMessages.length > 0) {
                this.ux.styledHeader(messages.getMessage('BulkError'));
                errorMessages.forEach((errorMessage) => {
                    this.ux.log(errorMessage);
                });
            }
        }
        const formatOutput = [];
        for (const field in summary) {
            if (Object.prototype.hasOwnProperty.call(summary, field)) {
                formatOutput.push(field);
            }
        }
        formatOutput.splice(0, 1);
        if (isJob) {
            // remove url field
            // eslint-disable-next-line @typescript-eslint/ban-ts-comment
            // @ts-ignore
            delete summary['$'];
            this.ux.styledHeader(messages.getMessage('BulkJobStatus'));
        }
        else {
            this.ux.styledHeader(messages.getMessage('BatchStatus'));
        }
        this.ux.styledObject(summary, formatOutput);
        return summary;
    }
    /**
     * create and execute batches based on the record arrays; wait for completion response if -w flag is set with > 0 minutes
     * to get proper logging/printing to console pass the instance of UX that called this method
     *
     * @param job {Job}
     * @param records
     * @param sobjectType {string}
     * @param wait {number}
     */
    async createAndExecuteBatches(job, records, sobjectType, wait) {
        const batchesCompleted = 0;
        let batchesQueued = 0;
        const overallInfo = false;
        const batches = await this.splitIntoBatches(records);
        // The error handling for this gets quite tricky when there are multiple batches
        // Currently, we bail out early by calling an Error.exit
        // But, we might want to actually continue to the next batch.
        return (await Promise.all(batches.map(async (batch, i) => {
            const newBatch = job.createBatch();
            return new Promise((resolve, reject) => {
                newBatch.on('error', (err) => {
                    // reword no external id error message to direct it to org user rather than api user
                    if (err.message.startsWith('External ID was blank')) {
                        err.message = messages.getMessage('ExternalIdRequired', [sobjectType]);
                        job.emit('error', err);
                    }
                    if (err.message.startsWith('Polling time out')) {
                        err.message = this.parseTimeOutError(err);
                        // using the reject method for all of the promises wasn't handling errors properly
                        // so emit a 'error' on the job.
                        job.emit('error', new core_1.SfError(err.message, 'Time Out', [], 69));
                    }
                    this.ux.stopSpinner('Error');
                });
                newBatch.on('queue', 
                // eslint-disable-next-line @typescript-eslint/no-misused-promises
                async () => {
                    batchesQueued++;
                    if (batchesQueued === batches.length) {
                        /* jsforce clears out the id after close, but you should be able to close a job
                    after the queue, so add it back so future batch.check don't fail.*/
                        const id = job.id;
                        await job.close();
                        job.id = id;
                    }
                });
                if (!wait) {
                    newBatch.on('queue', 
                    // we're using an async method on an event listener which doesn't fit the .on method parameter types
                    // eslint-disable-next-line @typescript-eslint/no-misused-promises
                    async (batchInfo) => {
                        this.ux.log(messages.getMessage('CheckStatusCommand', [i + 1, batchInfo.jobId, batchInfo.id]));
                        const result = await newBatch.check();
                        if (result.state === 'Failed') {
                            reject(result.stateMessage);
                        }
                        else {
                            resolve(batchInfo);
                        }
                    });
                }
                else {
                    resolve(this.waitForCompletion(newBatch, batchesCompleted, overallInfo, i + 1, batches.length, wait));
                }
                newBatch.execute(batch, (err) => {
                    if (err) {
                        reject(err);
                    }
                });
            });
        })));
    }
    /**
     * The timeout error handling is messy so to increase readability
     * break it out into it's own method
     *
     * @param err The timeout Error
     * @private
     */
    parseTimeOutError(err) {
        const jobIdIndex = err.message.indexOf('750');
        const batchIdIndex = err.message.indexOf('751');
        const message = messages.getMessage('TimeOut', [
            err.message.substr(jobIdIndex, 18),
            err.message.substr(batchIdIndex, 18),
        ]);
        this.ux.log('');
        this.ux.log(message);
        process.exitCode = 69;
        return message;
    }
    /**
     * register completion event listeners on the batch
     * exposed for unit testing
     *
     * @param newBatch
     * @param batchesCompleted
     * @param overallInfo
     * @param batchNum
     * @param totalNumBatches
     * @param waitMins
     */
    async waitForCompletion(newBatch, batchesCompleted, overallInfo, batchNum, totalNumBatches, waitMins) {
        return new Promise((resolve, reject) => {
            newBatch.on('queue', 
            // we're using an async method on an event listener which doesn't fit the .on method parameter types
            // eslint-disable-next-line @typescript-eslint/no-misused-promises
            async (batchInfo) => {
                const result = await newBatch.check();
                if (result.state === 'Failed') {
                    reject(result.stateMessage);
                }
                else {
                    if (!overallInfo) {
                        this.ux.log(messages.getMessage('PollingInfo', [POLL_FREQUENCY_MS / 1000, batchInfo.jobId]));
                        overallInfo = true;
                    }
                }
                this.ux.log(messages.getMessage('BatchQueued', [batchNum, batchInfo.id]));
                newBatch.poll(POLL_FREQUENCY_MS, waitMins * 60000);
            });
            // we're using an async method on an event listener which doesn't fit the .on method parameter types
            // eslint-disable-next-line @typescript-eslint/no-misused-promises
            newBatch.on('response', async (results) => {
                const summary = await newBatch.check();
                this.bulkStatus(summary, results, batchNum);
                batchesCompleted++;
                if (batchesCompleted === totalNumBatches) {
                    resolve(await this.fetchAndDisplayJobStatus(summary.jobId));
                }
            });
        });
    }
    /**
     * registers the listener in charge of distributing all csv records into batches
     *
     * @param readStream - the read stream
     * @returns {Promise<Batches>}
     */
    async splitIntoBatches(readStream) {
        // split all records into batches
        const batches = [];
        let batchIndex = 0;
        let batchBytes = 0;
        let batchHeaderBytes = 0;
        batches[batchIndex] = [];
        return await new Promise((resolve, reject) => {
            const parser = parse({
                columns: true,
                // library option is snakecase
                // eslint-disable-next-line camelcase
                skip_empty_lines: true,
                bom: true,
            });
            readStream.pipe(parser);
            parser.on('data', (element) => {
                if (!batchHeaderBytes) {
                    // capture header byte length
                    batchHeaderBytes = Buffer.byteLength((0, sync_1.stringify)([Object.keys(element)]) + '\n', 'utf8');
                    batchBytes = batchHeaderBytes;
                }
                // capture row byte length
                const rowBytes = Buffer.byteLength((0, sync_1.stringify)([Object.values(element)]) + '\n', 'utf8');
                if (batches[batchIndex].length === BATCH_RECORDS_LIMIT || rowBytes + batchBytes > BATCH_BYTES_LIMIT) {
                    // TODO: we can start processing this batch here
                    // we need event listeners to remove all of the `await new Promise`
                    // next batch
                    batchIndex++;
                    batches[batchIndex] = [];
                    // reset file size to just the headers
                    batchBytes = batchHeaderBytes;
                }
                batchBytes += rowBytes;
                batches[batchIndex].push(element);
            });
            parser.on('error', (err) => {
                readStream.destroy();
                reject(core_1.SfError.wrap(err));
            });
            parser.on('end', () => {
                readStream.destroy();
                resolve(batches);
            });
        });
    }
}
exports.Batcher = Batcher;
//# sourceMappingURL=batcher.js.map